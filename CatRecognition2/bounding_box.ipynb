{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision, torch, os, tqdm\n",
    "from constants import *\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\University\\SideProjects\\CatRecognition\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\University\\SideProjects\\CatRecognition\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "class BoundindBox:\n",
    "    def __init__(self, x1, y1, x2, y2, confidence=float, class_id=None):\n",
    "        self.x1, self.y1, self.x2, self.y2 = x1, y1, x2, y2\n",
    "        self.confidence = confidence\n",
    "        self.class_id = class_id\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"BoundindBox({self.x1}, {self.y1}, {self.x2}, {self.y2}, {self.confidence}, {self.class_id})\"\n",
    "\n",
    "def calculate_boxes(file_path: str) -> list[BoundindBox]:\n",
    "    if not file_path.endswith('.jpg'):\n",
    "        print(f\"Skipping {file_path}\")\n",
    "        return []\n",
    "    \n",
    "    # get image and convert to black and white\n",
    "    image = Image.open(file_path).convert('RGB')\n",
    "    image = torchvision.transforms.ToTensor()(image).to(device)\n",
    "    prediction = model([image])\n",
    "    boxes = prediction[0]['boxes']\n",
    "    \n",
    "    return [BoundindBox(*box, confidence=confidence, class_id=class_id) for box, confidence, class_id in zip(boxes, prediction[0]['scores'], prediction[0]['labels'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.24it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.80it/s]\n",
      " 35%|███▌      | 7/20 [00:01<00:03,  4.02it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot write mode RGBA as JPEG",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\University\\SideProjects\\CatRecognition\\.venv\\Lib\\site-packages\\PIL\\JpegImagePlugin.py:650\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     rawmode \u001b[38;5;241m=\u001b[39m \u001b[43mRAWMODE\u001b[49m\u001b[43m[\u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'RGBA'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# draw box, the higher the confidence, the thicker the box\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     draw\u001b[38;5;241m.\u001b[39mrectangle([box\u001b[38;5;241m.\u001b[39mx1, box\u001b[38;5;241m.\u001b[39my1, box\u001b[38;5;241m.\u001b[39mx2, box\u001b[38;5;241m.\u001b[39my2], outline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(box\u001b[38;5;241m.\u001b[39mconfidence \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m---> 27\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_folder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\University\\SideProjects\\CatRecognition\\.venv\\Lib\\site-packages\\PIL\\Image.py:2439\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2436\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2439\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2440\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   2441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[1;32md:\\University\\SideProjects\\CatRecognition\\.venv\\Lib\\site-packages\\PIL\\JpegImagePlugin.py:653\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    652\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot write mode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mim\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as JPEG\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 653\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    655\u001b[0m info \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mencoderinfo\n\u001b[0;32m    657\u001b[0m dpi \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mround\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))]\n",
      "\u001b[1;31mOSError\u001b[0m: cannot write mode RGBA as JPEG"
     ]
    }
   ],
   "source": [
    "# get all folders in PHOTOS_FOLDER \n",
    "folders = os.listdir(PHOTOS_FOLDER)[:10]\n",
    "\n",
    "# calculate boxes for each image in each folder, export to PROCESSED_PHOTOS_FOLDER with the same structure\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(PHOTOS_FOLDER, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    processed_folder_path = os.path.join(PROCESSED_PHOTOS_FOLDER, folder)\n",
    "    os.makedirs(processed_folder_path, exist_ok=True)\n",
    "\n",
    "    for file in tqdm.tqdm(os.listdir(folder_path)):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        boxes = calculate_boxes(file_path)\n",
    "        image = Image.open(file_path)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        for box in boxes:\n",
    "            # only get cat\n",
    "            if box.class_id != 17:\n",
    "                continue\n",
    "            if box.confidence < 0.5:\n",
    "                continue\n",
    "            # draw box, the higher the confidence, the thicker the box\n",
    "            draw.rectangle([box.x1, box.y1, box.x2, box.y2], outline='red', width=int(box.confidence * 10))\n",
    "            \n",
    "        image.save(os.path.join(processed_folder_path, file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
